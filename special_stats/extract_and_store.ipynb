{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e3f5962",
   "metadata": {},
   "source": [
    "Collects data from the API of the _Saisonmanager_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57b2101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import httpx\n",
    "import pandas as pd\n",
    "\n",
    "API_URL = \"https://saisonmanager.de/api/v2\"\n",
    "\n",
    "leagues_url = API_URL + \"/leagues.json\"\n",
    "league_url = API_URL + \"/leagues/{league_id}.json\"\n",
    "standings_url = API_URL + \"/leagues/{league_id}/table.json\"\n",
    "scorers_url = API_URL + \"/leagues/{league_id}/scorer.json\"\n",
    "schedule_url = API_URL + \"/leagues/{league_id}/schedule.json\"\n",
    "game_url = API_URL + \"/games/{game_id}.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e90e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_leagues(filename = \"leagues.pkl\"):\n",
    "    # Collect Leagues\n",
    "    print('Collecting leagues')\n",
    "    leagues = pd.read_json(leagues_url)\n",
    "    leagues.to_pickle(filename)\n",
    "    print('Done')\n",
    "    print()\n",
    "    \n",
    "def collect_players(filename = \"scorers.pkl\"):\n",
    "    # Collect Scorers\n",
    "    # collect scorer data for the leagues; need to check that the URL can\n",
    "    # be reached beforehand because a few fail with a 500 Internal Server Error\n",
    "    print('Collecting scorers')\n",
    "    leagues = pd.read_json(leagues_url)\n",
    "    scorers = {\n",
    "        league_id: pd.read_json(scorers_url.format(league_id=league_id))\n",
    "        for league_id in leagues.id\n",
    "        if httpx.head(scorers_url.format(league_id=league_id)).is_success\n",
    "    }\n",
    "    # create additional column containing league ids\n",
    "    league_ids = pd.Series(\n",
    "        itertools.chain(\n",
    "            *[\n",
    "                itertools.repeat(league_id, len(scorerdata))\n",
    "                for league_id, scorerdata in scorers.items()\n",
    "            ]\n",
    "        ),\n",
    "        name=\"league_id\",\n",
    "    )\n",
    "    # create dataframe from the combined schedules\n",
    "    players = pd.concat(scorers.values(), ignore_index=True)\n",
    "    # combine the dataframes into one with all the columns\n",
    "    playerdata = pd.concat([league_ids, players], axis=\"columns\")\n",
    "    playerdata.to_pickle(filename)\n",
    "    print('Done')\n",
    "    print()\n",
    "    \n",
    "def collect_matches(filename = \"matches.pkl\"):\n",
    "    # Collect schedules\n",
    "    # collect schedule data for the leagues; need to check that the URL can\n",
    "    # be reached beforehand because a fewfail with a 500 Internal Server Error\n",
    "    print('Collecting schedules')\n",
    "    leagues = pd.read_json(leagues_url)\n",
    "    schedules = {\n",
    "        league_id: pd.read_json(schedule_url.format(league_id=league_id))\n",
    "        for league_id in leagues.id\n",
    "        if httpx.head(schedule_url.format(league_id=league_id)).is_success\n",
    "    }\n",
    "\n",
    "    # create additional column containing league ids\n",
    "    league_ids = pd.Series(\n",
    "        itertools.chain(\n",
    "            *[\n",
    "                itertools.repeat(league_id, len(schedule))\n",
    "                for league_id, schedule in schedules.items()\n",
    "            ]\n",
    "        ),\n",
    "        name=\"league_id\",\n",
    "    )\n",
    "\n",
    "    # create matches dataframe from the combined schedules\n",
    "    matches = pd.concat(schedules.values(), ignore_index=True)\n",
    "    # unpack the JSON strings in the result column into a dataframe\n",
    "    results = pd.json_normalize(matches[\"result\"])\n",
    "    # use nullable integer type\n",
    "    results[\"home_goals\"] = results[\"home_goals\"].astype(\"Int64\")\n",
    "    results[\"guest_goals\"] = results[\"guest_goals\"].astype(\"Int64\")\n",
    "    # remove JSON result column\n",
    "    matches = matches.drop(columns=[\"result\"])\n",
    "    # combine the three dataframes into one with all the columns\n",
    "    matches = pd.concat([league_ids, results, matches.reset_index()], axis=\"columns\")\n",
    "    matches.to_pickle(filename)\n",
    "    print('Done')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1a571f",
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_leagues()\n",
    "collect_players()\n",
    "collect_matches()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
